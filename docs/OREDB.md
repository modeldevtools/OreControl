# ORE DB

ORE DB is
- a collection of sql DDL scripts to create a Database for storing ORE Parameters, trade data and marketdata/fixingdata.
- perl scripts to transform given xml files (e.g. examples) and marketdata/fixingdata into sql DML scripts.
- the perl scripts and the (generated) SQL DDL/DML scripts are executed with windows cmd-shell scripts.
- currently MS SQL Server and MYSQL are supported. The proof-of-concept final database extraction/ORE running is only possible with MS SQL Server as it supports XML-creation for SQL Queries.

## SQL DDL scripts

### Tables
The main rationale was to  
a) follow the structure set up by the xml schemata  
b) have relational intgrity where possible  

Following sql scripts define the tables:
- MdatTables.sql: all marketdata related tables (marketdata, fixingdata and covariancedata)
- NettingTables.sql: all tables for nettingset definitions
- OreParametersTables.sql: all tables for the ore parameter definitions
- PortfolioTables.sql: all tables for the portfolio definitions
- PricingengineTables.sql: all tables for the prixing engine definitions
- ResultsTables.sql: all tables for ORE results.
- SensitivityanalysisTables.sql: all tables for the sensitivity analysis definitions
- SimulationTables.sql: all tables for the simulation definitions
- StresstestTables.sql: all tables for the stresstest definitions
- TodaysmarketTables.sql: all tables for the todaysmarket definitions
- TypesTables.sql: all tables for the referenced types.
- ConventionsTables.sql: all tables for the convention definitions
- CurveConfigurationTables.sql: all tables for the curve configuration definitions

For filling the TodaysmarketCurveSpec Table (which is required as a relational reference of curve configuration fields to curve specs) there are trigger definitions on the TodaysmarketTables that define a curve spec for each supported database:
- TodaysmarketTableTriggerMSSQL.sql
- TodaysmarketTableTriggerMYSQL.sql

For details see the [SchemaSpy generated documentation](schemaDoc/index.html)

### XMLselectionViews
These are MS SQL Server XML query Views to extract the data into usable xml text. The logic of this extraction is detailed in [https://rkapl123.github.io/SQLServerXML.html](https://rkapl123.github.io/SQLServerXML.html)

## SQL DML script generation

DML scripts are generated by perl scripts into the Data folder.

### ORE Parameters and Trade data
The cmd shell script runConvertXML2SQL.cmd (calls the perl script convertXML2SQL.pl) is used for the extraction of XML from ORE Parameter and Trade Data and conversion into DDL.
This can be either done for the provided Examples (as is preconfigured) or for other files. Configuration of the files to be taken is either done in convertXML2SQL.pl (default values)
```perl
# set this to your ORE Root folder
my $oreRoot = ($ARGV[0] ? $ARGV[0] : '../../Engine');
# set this to the folder where configuration files are located
my $configDir = ($ARGV[1] ? $ARGV[1] : "$oreRoot/Examples/Input");
# set this to the xsd schema definitions (should be the ones from the ORE Engine)
my $xsdDir = ($ARGV[2] ? $ARGV[2] : "$oreRoot/xsd");
# set this to your analysis input folder (to translate portfolio, ore parameters, netting sets and simulation/stresstest/sensitivity parameters)
my $inputDir = ($ARGV[3] ? $ARGV[3] : "$oreRoot/Examples/Example_1/Input");
# leave empty to process standard examples
$inputDir = "" if !$ARGV[0];
```
or using the provided arguments, where

- ARG1 .. oreRoot - ORE Root folder
- ARG2 .. configDir - configuration files folder
- ARG3 .. xsdDir - xsd schema definitions folder
- ARG4 .. inputDir - analysis input folder

The convertXML2SQL.pl script requires following packages to be installed: ```XML::LibXML; Scalar::Util```

To produce a correct running sql script (relational integrity), it is important that the parts (e.g. yield curves, etc.) in the parametrization files are ordered following their dependency.
As an example: A yield curve (e.g. JPY3M) depending on another yield curve (ProjectionCurveLong: JPY6M) needs to be put AFTER the depending yield curve, so JPY3M should be after JPY6M.

### Market-, Covariance- and Fixing data
The cmd shell script runConvertMarketdata2SQL.cmd (calls the perl script convertMarketdata2SQL.pl) is used for the extraction of text from ORE marketdata/covariancedata/fixingdata and conversion into DDL.
This can be either done for the provided Examples (as is preconfigured) or for other files. Configuration of the files to be taken is either done in convertXML2SQL.pl (default values)
```perl
# set this to your ORE Root folder
my $oreRoot = ($ARGV[0] ? $ARGV[0] : '../../Engine');
# set this to the path/filename of the marketdata/fixingdata/covariance files
my @marketdataFiles = (($ARGV[1] ? $ARGV[1] : "$oreRoot/Examples/Input/market_20160205.txt"),"marketdata_missing.txt");
my $fixingdataFile = ($ARGV[2] ? $ARGV[2] : "$oreRoot/Examples/Input/fixings_20160205.txt");
my $covarianceFile = ($ARGV[3] ? $ARGV[3] : "$oreRoot/Examples/Example_15/Input/covariance.csv");
```
or using the provided arguments, where

- ARG1 .. ORE Root folder
- ARG2 .. marketdata file
- ARG3 .. fixingdata file
- ARG4 .. covariance file

Because the relational integrity of quotes in the curve configuration is relying on Quote keys available in the MarketData Definitions table, another marketdata file "marketdata_missing.txt" is needed, which inserts the missing Quote keys.

## Database creation and filling

The DDL and DML scripts are executed with runOREDBScriptsSQLServer.cmd that runs each script using runSingleScript.cmd (used as a wrapper for different databases, currently MS SQL and MYSQL have been tested, MYSQL doesn't handle the XML query views)

## Database extraction and running ORE

As a proof of the concept, the script runXMLOutput.cmd fetches the Database-stored data for example 2 (Sensitivityanalysis and Stresstest from example 15) and writes it into respective xml files in folder OREDB. Subsequently ORE is started with the ore.xml parametrization and the extracted files.

The final OREControl suite would pass the XML strings in-memory to a modified ORE-App (using SWIG) and retrieve the results in-memory, too.
